{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f1c3ee",
   "metadata": {},
   "source": [
    "<img heigth=\"8\" src=\"https://i.imgur.com/826AqJI.png\" alt=\"pbs-enae\">\n",
    "\n",
    "<h1 align=\"left\">Análisis de datos con Python</h1>\n",
    "\n",
    "<h2 align=\"left\"><i>Estrategias de marketing basadas en datos</i></h2>\n",
    "\n",
    "<p align=\"left\">\n",
    "  <h3>Joseph F. Vergel-Becerra | Machine Learning - Tools and Skill Courses</h3>\n",
    "  <br>\n",
    "  <b>Last updated:</b> <i>16/02/2023</i>\n",
    "  <br><br>\n",
    "  <!-- <a href=\"#tabla-de-contenido\">Tabla de contenido</a> • -->\n",
    "  <a href=\"#referencias\">Referencias</a> •\n",
    "  <a href=\"#contribuir\">Contribuir</a>\n",
    "  <!-- <a href=\"#agradecimientos\">Agradecimientos</a> -->\n",
    "  <br><br>\n",
    "</p>\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "      <a href=\"https://img.shields.io/badge/version-0.1.0-blue.svg?cacheSeconds=2592000\">\n",
    "        <img src=\"https://img.shields.io/badge/version-0.1.0-blue.svg?cacheSeconds=2592000\" alt=\"Version\" height=\"18\">\n",
    "      </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/joefavergel/pbs-enae-python-beginners-course/blob/main/4-python-data-analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "      </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/joefavergel/pbs-enae-ml-course\" target=\"_parent\"><img src=\"https://img.shields.io/github/forks/joefavergel/pbs-enae-ml-course?style=social\" alt=\"Fork\"/>\n",
    "      </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "Ofrecer un servicio o producto a los clientes con un perfil de posible comprador, constituye un factor diferenciador en las estrategias comerciales y de marketing de las compañías e impacta drásticamente en el ahorro de recursos de estas divisiones. Es así como se define el concepto de *target* u objetivo en marketing, que no es más que la definición de los clientes potenciales o público general, que tiene como objetivo una determinada estrategia de marketing, a la hora de hacerles llegar los  productos o servicios de la compañía. En esta oportunidad **representaremos el brazo tecnológico de la división de marketing y comercialización de una institución bancaria** y plantearemos una solución predictiva sobre datos de campañas de marketing telefónico, con la que **predeciremos la probabilidad de que un cliente contrate un certificado de depósito a plazo fijo (CDP)**. De esta manera podremos ofrecerle a nuestros clientes con mayor probabilidad de suscripción, **campañas publicitarias acertadas que maximizen la captación de nuevos contratos** y que al mismo tiempo **reduzcan los costos publicitarios**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2dbc0ba",
   "metadata": {},
   "source": [
    "<a id='tabla-de-contenido'></a>\n",
    "## Tabla de contenido\n",
    "    \n",
    "<ol>\n",
    "    <li><a href=\"#1-preludio\"><b>Preludio</b></a></li>\n",
    "    <li><a href=\"#2-ingesta\"><b>Ingesta de datos</b></a></li>\n",
    "    <li><a href=\"#3-analisis\"><b>Análisis exploratorio y entendimiento de los datos</b></a></li>\n",
    "    <li><a href=\"#4-descriptiva\">Estadística descriptiva</a></li>\n",
    "    <ol type=\"a\">\n",
    "        <li><a href=\"#i-tendencia\">Medidas de tendencia central</a></li>\n",
    "        <li><a href=\"#ii-dispersion\">Medidas de dispersión</a></li>\n",
    "        <li><a href=\"#iii-correlacion\">Correlación y covarianza</a></li>\n",
    "    </ol>\n",
    "    <li><a href=\"#5-calidad\">Análisis de calidad de los datos</a></li>\n",
    "    <ol type=\"a\">\n",
    "        <li><a href=\"#i-faltantes\">Detección de valores faltantes</a></li>\n",
    "        <li><a href=\"#ii-outliers\">Detección de outliers</a></li>\n",
    "    </ol>\n",
    "    <li><a href=\"#ejercicios\"><b>Ejercicios caso práctico: \"Análisis de Datos con Python\"</b></a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ba1d4",
   "metadata": {},
   "source": [
    "<a id=\"1-preludio\"></a>\n",
    "## 1. Preludio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from pathlib import Path\n",
    "from packaging import version\n",
    "import sklearn\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "print(\"[INFO] Este proyecto requiere python 3.8 o superior y Scikit-Learn 1.0.1 o superior.\")\n",
    "assert sys.version_info >= (3, 8)\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
    "print(\"[INFO] Versiones vificadas exitosamente!\")\n",
    "\n",
    "\n",
    "def css_styling():\n",
    "    styles_path = Path(f\"./styles/custom.css\")\n",
    "    if not styles_path.is_file():\n",
    "        Path(\"styles\").mkdir(parents=True, exist_ok=True)\n",
    "        url = f\"https://github.com/joefavergel/pbs-enae-ml-course/blob/main/styles/custom.css?raw=true\"\n",
    "        urllib.request.urlretrieve(url, styles_path)\n",
    "\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "\n",
    "\n",
    "css_styling()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ffddc69",
   "metadata": {},
   "source": [
    "<a id=\"2-ingesta\"></a>\n",
    "## 2. Ingesta de datos\n",
    "\n",
    "La ingesta de datos a través de archivos es una práctica común en la gestión de información. Consiste en la importación de datos desde archivos, ya sean de texto, hojas de cálculo, bases de datos o cualquier otro formato, a un sistema o aplicación para su posterior procesamiento y análisis. Esta técnica es esencial para la mayoría de las empresas y organizaciones, ya que les permite recolectar y gestionar grandes cantidades de información de manera eficiente. En esta ocasión ingestaremos un base de datos de clientes del sector bancario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "\n",
    "DATASET = \"banking-marketing-targets\"\n",
    "DATA_PATH = f\"datasets/{DATASET}/\"\n",
    "\n",
    "\n",
    "def download_dataset(dataset: str):\n",
    "    zipfile_path = Path(f\"datasets/{dataset}.zip\")\n",
    "    if not zipfile_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = f\"https://github.com/joefavergel/datasets/blob/main/{dataset}.zip?raw=true\"\n",
    "        urllib.request.urlretrieve(url, zipfile_path)\n",
    "    Path(f\"datasets/{dataset}\").mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        ZipFile(zipfile_path).extractall(f\"datasets/{dataset}\")\n",
    "        print(f\"[INFO] Dataset \\'{dataset}\\' downloaded and uncompressed correctly!\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Exception] There's been a problem: {e}\")\n",
    "\n",
    "\n",
    "download_dataset(dataset=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344c689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\n",
    "    f\"[INFO] Los archivos presentes en \\\"{DATA_PATH}\\\":\"\n",
    "    f\"\\n\\n{os.listdir(DATA_PATH)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3aa5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"), sep=\";\")\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"), sep=\";\")\n",
    "\n",
    "train.rename(columns={\"y\": \"cd\"}, inplace=True)\n",
    "test.rename(columns={\"y\": \"cd\"}, inplace=True)\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(f\"[INFO] Training dataset dimnesions (rows, cols): {train.shape}\")\n",
    "    display(train.head())\n",
    "    \n",
    "    print(f\"\\n[INFO] testing dataset dimnesions (rows, cols): {test.shape}\")\n",
    "    display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71dcb3",
   "metadata": {},
   "source": [
    "<a id=\"3-analisis\"></a>\n",
    "## 3. Análisis exploratorio y entendimiento de los datos\n",
    "\n",
    "El analisis exploratorio de los datos (EDA por sus siglas en ingles) es como comunmente se denomina de forma tecnica a la fase de \"Descubra y visualice los datos para obtener información\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89fc6d70",
   "metadata": {},
   "source": [
    "### Información de las variables del *dataset*\n",
    "\n",
    "Datos del cliente:\n",
    "\n",
    "1. `edad` (numérico): edad del cliente.\n",
    "2. `job` (categórico): tipo de trabajo.\n",
    "3. `marital` (categórico): estado civil.\n",
    "4. `educación` (categórico): Nivel de escolaridad (studios primarios, secundarios o terciarios).\n",
    "5. `default` (*booleano*): ¿tiene algun credito en mora?\n",
    "6. `balance` (numérico): saldo promedio anual, en euros.\n",
    "7. `housing` (*booleano*): ¿tiene préstamo de vivienda?.\n",
    "8. `loan` (*booleano*): ¿tiene préstamo personal?.\n",
    "\n",
    "Las siguientes variables estan relacionadas con el último contacto de la campaña de marketing actual:\n",
    "\n",
    "9. `contact` (categórico): tipo de comunicación con el cliente.\n",
    "10. `day` (numérico): último día de contacto del mes.\n",
    "11. `month` (categórico): último mes de contacto del año.\n",
    "12. `duration` (numérico): duración del último contacto, en segundos.\n",
    "\n",
    "Otros atributos de las instancias:\n",
    "\n",
    "13. `campaign` (numérico): número de contactos realizados durante esta campaña y para este cliente, incluye último contacto.\n",
    "14. `pdays` (numérico): número de días que transcurrieron desde la última vez que se contactó al cliente en una campaña anterior, donde -1 significa que el cliente no fue contactado previamente.\n",
    "15. `previous` (numérico): número de contactos realizados antes de esta campaña y para este cliente \n",
    "16. `poutcome` (categórico): resultado de la campaña de marketing anterior.\n",
    "\n",
    "Variable objetivo (*target*) a predecir:\n",
    "\n",
    "17. `cd` (*booleano*): ¿El cliente ha suscrito un depósito a plazo?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48eab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75baecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Columns of trainig dataset: \\n\", train.columns)\n",
    "print(\"\\n[INFO] Columns of trainig dataset: \\n\", test.columns)\n",
    "print(\n",
    "    \"\\n[INFO] Difference between training columns set and testing columns set: \\n\",\n",
    "    set(train.columns) - set(test.columns)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fabaf577",
   "metadata": {},
   "source": [
    "<a id=\"4-descriptivaa\"></a>\n",
    "### 4. Estadistica descriptiva\n",
    "\n",
    "La estadística descriptiva es importante en el análisis de datos porque ***proporciona una manera sistemática de resumir y visualizar grandes conjuntos de datos***. Permite identificar patrones, tendencias y características de los datos, como ***la media, la mediana y la desviación estándar***. Esto puede ayudar a entender mejor los datos y a tomar decisiones informadas basadas en la información que proporcionan. Además, ***la estadística descriptiva es una herramienta esencial para comunicar los hallazgos*** de una manera clara y efectiva a otras personas.\n",
    "\n",
    "**Visualización de conteos de datos e histogramas de variables numéricas continuas**\n",
    "\n",
    "La importancia de la visualización de variables categóricas y de variables numéricas continuas se puede resumir en los siguientes puntos:\n",
    "\n",
    "- Ayuda a comprender y comunicar patrones y tendencias en los datos.\n",
    "- Las variables categóricas representan características o atributos que se dividen en categorías o grupos discretos, mientras que las variables numéricas continuas representan valores que se pueden medir y se ubican en una escala continua.\n",
    "- Al visualizar estas variables, se pueden identificar patrones, tendencias y relaciones en los datos.\n",
    "- Esto permite tomar decisiones más informadas y precisas.\n",
    "- Las visualizaciones pueden ayudar a comunicar los hallazgos a otras personas de manera clara y efectiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "high_carinality = [\"duration\", \"pdays\", \"age\", \"balance\"]\n",
    "categorical = train.select_dtypes(include=['object', 'int']).columns.values\n",
    "categorical = list(set(categorical) - set(high_carinality))\n",
    "features = categorical + high_carinality\n",
    "\n",
    "for column in features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if column in categorical:\n",
    "        count_plot = sns.countplot(x=train[column], data=train)\n",
    "        for p in count_plot.patches:\n",
    "            count_plot.annotate(\n",
    "                format(p.get_height()),\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha = 'center',\n",
    "                va = 'center',\n",
    "                xytext = (0, 10),\n",
    "                textcoords = 'offset points'\n",
    "            )\n",
    "        plt.title(f\"\\\"{column}\\\" Counts\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "    else:\n",
    "        dist_plot = sns.displot(data=train, x=column)\n",
    "        plt.title(f\"\\\"{column}\\\" Distribution\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fd2c4",
   "metadata": {},
   "source": [
    "Como la mayoría de los datos presentes en el *dataset* corresponden a variables categóricas, es necesario transformar primero dichas variables a numéricas y posterior a esto, volver a efectuar EDA sobre los datos transformados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68afcebd",
   "metadata": {},
   "source": [
    "<a href=\"i-tendencia\"></a>\n",
    "### 4.a. Medidas de tendencia central\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a target=\"_blank\">\n",
    "    <img width=\"700px\" src=\"https://i.imgur.com/KeJ6lbW.png\" alt=\"standard-correlation\">\n",
    "  </a>\n",
    "</p><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train.median(numeric_only=True)).rename(columns={0: \"median\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.mode(numeric_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "673d0bbb",
   "metadata": {},
   "source": [
    "<a href=\"#ii-dispersion\"></a>\n",
    "### 4.b. Medidas de dispersión\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a target=\"_blank\">\n",
    "    <img width=\"700px\" src=\"https://i.imgur.com/td7Vr3c.png\" alt=\"standard-correlation\">\n",
    "  </a>\n",
    "</p><br><br>\n",
    "\n",
    "Una desviación estándar baja indica que la mayor parte de los datos de una muestra tienden a estar agrupados cerca de su media (también denominada el valor esperado), mientras que una desviación estándar alta indica que los datos se extienden sobre un rango de valores más amplio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ea434",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.std(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc191a7",
   "metadata": {},
   "source": [
    "La desviación estándar es la raíz cuadrada positiva de la varianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cde197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.var(numeric_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "716eb4a0",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que la varianza puede verse muy influida por los valores atípicos y no se aconseja su uso cuando las distribuciones de las variables aleatorias tienen colas pesadas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ce4a599",
   "metadata": {},
   "source": [
    "<a href=\"iii-correlacion\"></a>\n",
    "### 4.c. Correlación y covarianza\n",
    "\n",
    "El análisis de correlaciones es importante en el análisis de datos porque permite identificar ***si existe una relación estadística significativa entre dos o más variables***. La ***la correlación puede ser positiva, negativa o nula***, y puede variar en fuerza y dirección. Al identificar la correlación entre variables, es posible comprender mejor cómo se relacionan y cómo afectan mutuamente.\n",
    "\n",
    "***Las correlaciones puede proporcionar información valiosa para la toma de decisiones y la planificación de estrategias***. Por ejemplo, puede ayudar a identificar variables que tienen un impacto significativo en el rendimiento de una empresa o a predecir cómo cambiará una variable si cambia otra.\n",
    "\n",
    "Ahora, sabiendo la importancia de las correlaciones revisemos el coficiente de correlacion lineal de Pearson:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a target=\"_blank\">\n",
    "    <img width=\"700px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1280px-Correlation_examples2.svg.png\" alt=\"standard-correlation\">\n",
    "  </a><br><br>\n",
    "  <b>Figura 1:</b> <i>Varios conjuntos de puntos (x, y), con el coeficiente de correlación de x e y para cada conjunto. La correlación refleja la fuerza y la dirección de una relación lineal (fila superior), pero no la pendiente de esa relación (centro), ni muchos aspectos de las relaciones no lineales (parte inferior). N.B.: la figura del centro tiene pendiente 0 pero en ese caso el coeficiente de correlación no está definido porque la varianza de Y es cero</i>¹⁶.\n",
    "</p><br>\n",
    "\n",
    "El coeficiente de correlación de Pearson va de –1 a 1. Cuando está cerca de 1, significa que hay una fuerte correlación positiva. Cuando el coeficiente es cercano a –1, significa que existe una fuerte correlación negativa o correlacion inversa. Finalmente, los coeficientes cercanos a 0 significan que no existe una correlación lineal. La Fig. 1 muestra varias distirbuciones de datos junto con el coeficiente de correlación entre sus ejes horizontal y vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_corr(data: pd.DataFrame, title: str, method: str = \"pearson\", annot: bool = True):\n",
    "    f,ax = plt.subplots(figsize=(10,8))\n",
    "    sns.heatmap(\n",
    "        data.corr(method=method),\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        annot=annot,\n",
    "        linewidths=.5,\n",
    "        fmt='.2f',\n",
    "        ax=ax\n",
    "    )\n",
    "    plt.title(f\"{method.title()}'s Correlation Coefficient between {title}\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae319215",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_corr(\n",
    "    train.select_dtypes(\"number\"),\n",
    "    title=\"the Main Numeric Features\",\n",
    "    method=\"pearson\",\n",
    "    annot=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50971d75",
   "metadata": {},
   "source": [
    "Observamos que las correlaciones mas fuertes existe entre las variables \"pdays\" y \"previous\" y las variables \"day\" y \"campaign\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\n",
    "def plot_scatter_and_corr(\n",
    "    dataframe: pd.DataFrame,\n",
    "    x_feature: str,\n",
    "    y_feature:str,\n",
    "    ax: np.array = None,\n",
    "    pos: int = None\n",
    "):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "    pos = 0 if pos is None else 1\n",
    "\n",
    "    r, _ = scipy.stats.pearsonr(\n",
    "        dataframe[x_feature].tolist(), dataframe[y_feature].tolist()\n",
    "    )\n",
    "    tau, _ = scipy.stats.kendalltau(\n",
    "        dataframe[x_feature].tolist(), dataframe[y_feature].tolist()\n",
    "    )\n",
    "    ax[pos].scatter(\n",
    "        dataframe[x_feature].tolist(),\n",
    "        dataframe[y_feature].tolist(),\n",
    "        alpha=0.2,\n",
    "        color=\"#FC5185\" if pos == 1 else \"#364F6B\",\n",
    "        label=f\"r={np.round(r, 2)}, tau={np.round(tau, 2)}\"\n",
    "    )\n",
    "    ax[pos].set_xlabel(x_feature)\n",
    "    ax[pos].set_ylabel(y_feature)\n",
    "    ax[pos].set_title(f\"{y_feature} vs. {x_feature}\")\n",
    "    ax[pos].tick_params(axis='x', rotation=45)\n",
    "    ax[pos].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dccfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature, y_feature = \"pdays\", \"previous\"\n",
    "ax = plot_scatter_and_corr(\n",
    "    dataframe=train, x_feature=x_feature, y_feature=y_feature,\n",
    ")\n",
    "\n",
    "x_feature, y_feature = \"day\", \"campaign\"\n",
    "ax = plot_scatter_and_corr(\n",
    "    dataframe=train, x_feature=x_feature, y_feature=y_feature, ax=ax, pos=1\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_upper_triangular_dot(*args, **kwargs):\n",
    "    corr_tau = args[0].corr(args[1], method=method)\n",
    "    corr_text = f\"{corr_tau:2.2f}\".replace(\"0.\", \".\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "    marker_size = abs(corr_tau) * 10000\n",
    "    ax.scatter(\n",
    "        [.5],\n",
    "        [.5],\n",
    "        marker_size,\n",
    "        [corr_tau],\n",
    "        alpha=0.6,\n",
    "        cmap=\"coolwarm\",\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        transform=ax.transAxes\n",
    "    )\n",
    "    font_size = abs(corr_tau) * 40 + 5\n",
    "    ax.annotate(\n",
    "        corr_text, [.5, .5,], \n",
    "        xycoords=\"axes fraction\",\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        fontsize=font_size\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab66b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.seterr(invalid='ignore', over='ignore')\n",
    "\n",
    "method = \"pearson\"\n",
    "g = sns.PairGrid(train, aspect=1.0, diag_sharey=False)\n",
    "g.map_lower(sns.regplot, lowess=True, ci=None, line_kws={'color': 'black'})\n",
    "g.map_diag(sns.histplot, kde=False, bins=10)\n",
    "g.map_upper(corr_upper_triangular_dot, method=method)\n",
    "g.fig.suptitle(\n",
    "    f\"{method.title()}'s Correlation Coefficient between Dataset Features\",\n",
    "    fontsize=32\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1aeff0",
   "metadata": {},
   "source": [
    "<a id=\"5-calidad\"></a>\n",
    "# 5. Análisis de la calidad de Datos\n",
    "\n",
    "Análisis de la Calidad de los Datos en el Contexto de un Curso de Python y Análisis de Datos:\n",
    "\n",
    "El \"Análisis de la Calidad de los Datos\" se refiere al proceso de inspeccionar y asegurar que los datos empleados para análisis sean de alta calidad, lo que significa que sean precisos, confiables y adecuados para el propósito del análisis. Dentro de este contexto, se pueden destacar dos pasos cruciales:\n",
    "\n",
    "a. Detección de datos faltantes\n",
    "b. Detección de *outliers* (valores atípicos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da948ac1",
   "metadata": {},
   "source": [
    "<a id=\"i-faltantes\"></a>\n",
    "## 5.a. Detección de valores faltantes\n",
    "\n",
    " El análisis de valores faltantes es importante en el análisis de datos porque los valores faltantes pueden ***afectar la validez y la precisión de los resultados del análisis***. Los valores faltantes pueden ocurrir por diversas razones, como errores en la entrada de datos o la falta de respuesta a una pregunta en una encuesta. Al analizar los valores faltantes, es posible identificar patrones o sesgos en los datos y tomar medidas para corregirlos. En general, el análisis de valores faltantes es esencial para ***asegurar la integridad y confiabilidad de los resultados del análisis de datos***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install missingno prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be51e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "train.replace(\"unknown\", np.nan, inplace=True)\n",
    "test.replace(\"unknown\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7546467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def quantify_missing(dataframe: pd.DataFrame, tol: float):\n",
    "    missing_value = dataframe.isnull().mean() * 100\n",
    "    missing_value_dict = missing_value.to_dict()\n",
    "    missing_percentage = missing_value > tol\n",
    "    missing_percentage = missing_percentage.to_dict()\n",
    "    count = 0\n",
    "    table = PrettyTable(\n",
    "        ['Feature', 'Missing Value Percentage'], float_format='3.2'\n",
    "    )\n",
    "    features = []\n",
    "    for key in missing_percentage:\n",
    "        if missing_percentage[key]:\n",
    "            table.add_row([key, np.round(missing_value_dict[key], 8)])\n",
    "            count = count + 1\n",
    "            features.append(key)\n",
    "    print(table)\n",
    "    print('Total quantified features:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41022de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Percentages of missing values for the training dataset (rows: {train.shape[0]}):\")\n",
    "quantify_missing(dataframe=train, tol=0.0)\n",
    "\n",
    "print(f\"\\n[INFO] Percentages of missing values for the testing dataset (rows: {test.shape[0]}):\")\n",
    "quantify_missing(dataframe=test, tol=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1436bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Analysis of missing values for the training dataset (rows: {train.shape[0]}):\")\n",
    "msno.bar(train)\n",
    "plt.show()\n",
    "\n",
    "msno.matrix(train)\n",
    "plt.show()\n",
    "\n",
    "msno.heatmap(train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"contact\"].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"poutcome\"].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2c490",
   "metadata": {},
   "source": [
    "<a id=\"ii-outliers\"></a>\n",
    "## 5.b. Detección de *outliers*\n",
    "\n",
    "**Detección de Anomalías Univariada: Método de la desviación estándar**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a target=\"_blank\">\n",
    "    <img width=\"400px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Empirical_rule_histogram.svg/1280px-Empirical_rule_histogram.svg.png\" alt=\"a-b\">\n",
    "  </a><br>\n",
    "  <b>Figura 6:</b> <i>Para una distribución aproximadamente normal, los valores comprendidos en un intervalo de semiancho una desviación típica respecto a la media aritmética de la muestra, abarcan el 68% de los datos; mientras que dos desviaciones de semiancho abarcan el 95%; y tres deviaciones de semiancho incluyen el 99.7%. Los porcentajes mostrados son probabilidades teóricas redondeadas, destinadas solo a aproximar los datos empíricos derivados de una población normal.</i>²²\n",
    "</p><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "²² <a href=\"https://es.wikipedia.org/wiki/Regla_68-95-99.7\">Regla 68-95-99.7</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a31323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "\n",
    "subtrain = deepcopy(train.sample(N_SAMPLES))\n",
    "subtrain.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ab320",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"balance\"\n",
    "data = subtrain[target].tolist()\n",
    "sigma = 5\n",
    "data_mean, data_std = np.mean(data), np.std(data)\n",
    "cut_off = data_std * sigma\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outlier_flag = pd.Series([True if (x < lower or x > upper) else False for x in data ])\n",
    "print(outlier_flag.value_counts(normalize=True))\n",
    "outliers = [x for x in data if (x < lower or x > upper)]\n",
    "print(\n",
    "    \"\\n[INFO] Some possible outliers according to the standard deviation method for the \"\n",
    "    f\"target \\\"{target}\\\"\\n\", np.random.choice(outliers, 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Skewness of \\\"{target}\\\": %f\" % subtrain[target].skew())\n",
    "print(f\"[INFO] Kurtosis of \\\"{target}\\\": %f\" % subtrain[target].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e5f120",
   "metadata": {},
   "source": [
    "Los datos se consideran Gaussianos si la asimetría (*Skewness*) está entre -2 y +2 y la curtosis está entre -7 y +7.²²<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "²² <a href=\"https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/Simon#:~:text=The%20values%20for%20asymmetry%20and,between%20%E2%80%907%20to%20%2B7.\">Testing normality including skewness and kurtosis</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278ebf8",
   "metadata": {},
   "source": [
    "**Detección de Anomalías Univariada:** ***Machine Learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isolation_forest = IsolationForest(n_estimators=100, random_state=42)\n",
    "isolation_forest.fit(subtrain[target].values.reshape(-1, 1))\n",
    "xx = np.linspace(subtrain[target].min(), subtrain[target].max(), len(subtrain)).reshape(-1,1)\n",
    "anomaly_score = isolation_forest.decision_function(xx)\n",
    "outlier_flag = isolation_forest.predict(xx)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(xx, anomaly_score, label='Anomaly score')\n",
    "plt.fill_between(\n",
    "    xx.T[0],\n",
    "    np.min(anomaly_score),\n",
    "    np.max(anomaly_score), \n",
    "    where=outlier_flag==-1,\n",
    "    color='r', \n",
    "    alpha=.4,\n",
    "    label='Outlier region'\n",
    ")\n",
    "plt.legend()\n",
    "plt.ylabel('Anomaly score')\n",
    "plt.xlabel(target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_flag = pd.Series(outlier_flag).replace([-1, 1], [False, True])\n",
    "print(outlier_flag.value_counts(normalize=True))\n",
    "print(\n",
    "    \"\\n[INFO] Some possible outliers according to the standard deviation methodod for the \"\n",
    "    f\"target \\\"{target}\\\"\\n\", subtrain[outlier_flag][target].sample(20).tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246df0f8",
   "metadata": {},
   "source": [
    "<a id=\"ejercicios\"></a>\n",
    "## 6. Ejercicios caso práctico: \"Análisis de Datos con Python\"\n",
    "\n",
    "1. Replique la sección \"Análisis Exploratorio de los datos\" presentada en este `Jupyter notebook`, para el *dataset* que se descargará y descomprimirá  al ejecutar la siguiente celda de codigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "\n",
    "DATASET = \"titanic-dataset\"\n",
    "DATA_PATH = f\"datasets/{DATASET}/\"\n",
    "\n",
    "\n",
    "def load_traffic_congestion_data(dataset: str):\n",
    "    zipfile_path = Path(f\"datasets/{dataset}.zip\")\n",
    "    if not zipfile_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = f\"https://github.com/joefavergel/datasets/blob/main/{dataset}.zip?raw=true\"\n",
    "        urllib.request.urlretrieve(url, zipfile_path)\n",
    "    Path(f\"datasets/{dataset}\").mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        ZipFile(zipfile_path).extractall(f\"datasets/{dataset}\")\n",
    "        print(f\"[INFO] Dataset \\'{dataset}\\' downloaded and uncompressed correctly!\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Exception] There's been a problem: {e}\")\n",
    "\n",
    "\n",
    "load_traffic_congestion_data(dataset=DATASET)\n",
    "\n",
    "pd.read_csv(\"datasets/titanic-dataset/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec1c63",
   "metadata": {},
   "source": [
    "<a id='referencias'></a>\n",
    "## Referencias\n",
    "\n",
    "[1] Halswanter, T. (2016). *An Introduction to Statistics with Python: With Applications in the Life Sciences.* Springer.\n",
    "\n",
    "[2] Géron, A. (2022). *Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow.* \" O'Reilly Media, Inc.\".\n",
    "\n",
    "[3] VanderPlas, J. (2016). *Python data science handbook: Essential tools for working with data.* \" O'Reilly Media, Inc.\".\n",
    "\n",
    "[4] Aggarwal, C. C. (2015). *Data mining: the textbook (Vol. 1)*. New York: springer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c229a90",
   "metadata": {},
   "source": [
    "<a id='contribuir'></a>\n",
    "## Contribuir\n",
    "\n",
    "<p>Para correcciones, <i>bugs</i> o sugerencias, por favor escribe a <a href=\"mailto:joefavergel@gmail.com\">joefavergel@gmail.com</a> o directamente en el repositorio.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
